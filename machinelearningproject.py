# -*- coding: utf-8 -*-
"""MachineLearningProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EByiPZNBKxIB6UNbQXCO9S-3PGzgx2It

# Loading the dataset
"""

import pandas as pd

df = pd.read_csv('/content/campaign_responses.csv')
df.head()

"""# Data exploration and preprocessing"""

df.set_index('customer_id', inplace = True)
df.head()

df.info()

df.dtypes

"""# Encoding the dataset"""

from sklearn.preprocessing import LabelEncoder

obj_cols = df.select_dtypes(object).columns

for col in obj_cols:
  encoder = LabelEncoder()
  df[col] = encoder.fit_transform(df[col])

df.dtypes

"""# scaling the dataset"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[['age','annual_income','credit_score','no_of_children']] = scaler.fit_transform(df[['age', 'annual_income', 'credit_score', 'no_of_children']])

df.head()

"""# checking for outliers"""

import seaborn as sns
import matplotlib.pyplot as plt
for col in df:
    plt.figure(figsize=(10, 5))
    sns.boxplot(df)
    plt.title(f'Boxplot of {col}')
    plt.show()

"""# EDA ANALYSIS"""

import seaborn as sns
import matplotlib.pyplot as plt

# Compute the correlation matrix
corr = df.corr()
corr

# Generate a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.05)
plt.title('Correlation Matrix')
plt.show()

# Histograms for numerical features
numerical_features = ['age', 'annual_income', 'credit_score', 'no_of_children']
df[numerical_features].hist(bins=30, figsize=(15, 10))
plt.suptitle('Distribution of Numerical Features')
plt.show()

# Count plots for categorical features
categorical_features = ['gender', 'employed', 'marital_status', 'responded']
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
for idx, feature in enumerate(categorical_features):
    sns.countplot(x=feature, data=df, ax=axes[idx//2, idx%2])
    axes[idx//2, idx%2].set_title(f'Distribution of {feature}')
plt.tight_layout()
plt.show()

# Box plots to understand the distribution of numerical features with respect to the target variable
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
for idx, feature in enumerate(numerical_features):
    sns.boxplot(x='responded', y=feature, data=df, ax=axes[idx//2, idx%2])
    axes[idx//2, idx%2].set_title(f'{feature} by Response')
plt.tight_layout()
plt.show()

"""# Spliting the dataset"""

x = df.drop('responded',axis =1)
y = df['responded']

"""#Spliting the data into training and testing"""

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain,ytest = train_test_split(x,y,train_size=0.8)

"""# creating model


"""

from sklearn.tree import DecisionTreeClassifier
dtree = DecisionTreeClassifier()
dtree

"""# Training the model"""

dtree.fit(xtrain,ytrain)

"""# Prediction on training and testing data"""

trainpred = dtree.predict(xtrain)
testpred = dtree.predict(xtest)

"""# Evaluating the model"""

from sklearn.metrics import classification_report

print(classification_report(ytrain,trainpred))

print(classification_report(ytest,testpred))